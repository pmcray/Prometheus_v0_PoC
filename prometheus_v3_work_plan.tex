\documentclass{article}\usepackage[utf8]{inputenc}\usepackage{geometry}\geometry{a4paper, margin=1in}\usepackage{hyperref}\title{\textbf{Project Prometheus v0.3 Work Plan: The Evolving Thinker}}\author{Generated by Gemini}\date{\today}\begin{document}\maketitle\begin{abstract}This document outlines the detailed work plan for the next major phase of the Project Prometheus demonstrator, v0.3. Based on the "Ultraintelligence Implementation Detailed Breakdown," this phase, titled "The Evolving Thinker," moves beyond simple, direct self-modification and introduces the core components of true, open-ended recursive improvement. Where v0.2 learned to fix its own code, v0.3 will learn to \textbf{evolve entirely new solutions} and \textbf{generate its own curriculum}, beginning the transition into the formal, complex domains required for ultraintelligence.\end{abstract}\hrulefill\vspace{2em}\section{Task 1: Implement the Self-Modification Module (SMM) v1.1 - Evolutionary Search}\subsection{Rationale}As per Section 2.3 of the implementation plan, direct code modification is the most basic form of self-improvement. To unlock more creative and novel solutions, the system must be upgraded to perform \textbf{Evolutionary Search (Genetic Programming)}. This allows the agent to move beyond incremental patches and evolve entirely new algorithmic structures, enabling a broader search of the solution space.\subsection{Methodology}\begin{enumerate}    \item \textbf{Create the Gene Archive:} Implement a \texttt{GeneArchive} class. This module will be responsible for storing multiple versions ("genes") of key system components (e.g., different implementations of the \texttt{\_analyze\_complexity} method, or entire agent classes).    \item \textbf{Implement Genetic Operators in \texttt{CoderAgent}:} The \texttt{CoderAgent} will be upgraded with two new methods, acting as a sophisticated "genetic operator":        \begin{itemize}            \item \texttt{mutate(code)}: Takes a piece of code and, guided by the LLM, introduces a small, random but syntactically plausible change.            \item \texttt{crossover(code1, code2)}: Takes two successful "parent" versions of a function and, guided by the LLM, attempts to combine their best elements into a new "child" version.        \end{itemize}    \item \textbf{Update \texttt{MCSSupervisor} Workflow:} The main loop will be modified. Instead of just refactoring, the \texttt{PlannerAgent} can now set a goal like "Evolve a more efficient version of \texttt{inefficient\_sort.py} over 5 generations." The \texttt{MCSSupervisor} will then orchestrate the cycle of mutation/crossover, evaluation, and selection of the "fittest" solutions to be passed to the next generation.\end{enumerate}\subsection{Deliverables}\begin{itemize}    \item A \texttt{GeneArchive} module for storing and managing code versions.    \item An updated \texttt{CoderAgent} with \texttt{mutate} and \texttt{crossover} capabilities.    \item A new "evolutionary" run mode in the \texttt{MCSSupervisor}.\end{itemize}\subsection{Verification}The system can successfully run an evolutionary cycle for at least 5 generations on a target function. The final evolved function must be demonstrably more efficient than any version produced by the direct, single-shot refactoring of the v0.2 system.\section{Task 2: Evolve the Introspection and Evaluation Engine (IEE) v1.2 - Adaptive Curriculum}\subsection{Rationale}The current \texttt{BenchmarkAgent} generates problems of random, simple difficulty. To drive meaningful, open-ended growth, the IEE must become a true "reality check" (Section 2.3) that forces the agent to generalize by presenting it with a curriculum of ever-increasing difficulty.\subsection{Methodology}\begin{enumerate}    \item \textbf{Implement Performance Tracking:} The \texttt{MCSSupervisor} will now maintain a persistent log of the \texttt{CoderAgent}'s performance on all benchmarks, tracking success rates and the complexity of solved problems.    \item \textbf{Upgrade \texttt{BenchmarkAgent} to \texttt{CurriculumAgent}:} The \texttt{BenchmarkAgent} will be refactored into a \texttt{CurriculumAgent}. This agent will first consult the performance logs to assess the current capability level of the system. It will then dynamically generate a new benchmark that is slightly more difficult than the most complex problem solved to date.        \begin{itemize}            \item \textbf{Example:} If the agent has mastered sorting lists of integers, the \texttt{CurriculumAgent} might generate a benchmark that requires sorting a list of tuples by their second element.        \end{itemize}    \item \textbf{Implement Robust Meta-Judging:} The \texttt{EvaluatorAgent}'s causal analysis will be enhanced. It will not only check for complexity improvements but also for "specification gaming." For example, if a new sorting function is faster but fails on edge cases (like an empty list), the \texttt{EvaluatorAgent} must identify this as a regression, even if the basic tests pass.\end{enumerate}\subsection{Deliverables}\begin{itemize}    \item A persistent performance logging mechanism.    \item A new \texttt{CurriculumAgent} that can generate benchmarks of increasing difficulty.    \item An \texttt{EvaluatorAgent} with enhanced meta-judging capabilities to detect regressions and specification gaming.\end{itemize}\subsection{Verification}The system can successfully generate a sequence of at least three benchmarks, where each new benchmark is demonstrably more complex than the last. The \texttt{EvaluatorAgent} can correctly reject a proposed solution that is faster but less robust than the original.\section{Task 3: Begin Formal Domain Adaptation - Mathematical Theorem Proving}\subsection{Rationale}The ultimate goal of the initial testbed is to tackle automated mathematical theorem proving (Section 1.1). This requires integrating with formal proof assistants and shifting the agent's focus from writing Python code to writing formal proofs. This task lays the critical groundwork for that transition.\subsection{Methodology}\begin{enumerate}    \item \textbf{Integrate a Formal Proof Assistant:} Implement a new \texttt{LeanTool} that allows the agent to interact with the \href{https://leanprover.github.io/}{Lean proof assistant}. The tool will take a snippet of Lean code, execute it in a sandboxed environment, and return the output from the Lean server (e.g., "goals accomplished" or a type error).    \item \textbf{Update \texttt{CoderAgent} for Formal Language:} The \texttt{CoderAgent}'s prompts will be updated. When the goal is theorem proving, the prompt will provide context on Lean syntax and instruct the agent to generate proof steps in the Lean language.    \item \textbf{Update \texttt{CurriculumAgent} for Simple Theorems:} The \texttt{CurriculumAgent} will be given a new capability: generating simple mathematical propositions (e.g., "Prove that for any natural number n, n + 0 = n") that can serve as the initial benchmarks for the theorem-proving task.\end{enumerate}\subsection{Deliverables}\begin{itemize}    \item A \texttt{LeanTool} for interacting with the Lean proof assistant.    \item An updated \texttt{CoderAgent} capable of generating simple Lean proofs.    \item An updated \texttt{CurriculumAgent} capable of generating simple mathematical propositions.\end{itemize}\subsection{Verification}The \texttt{CoderAgent} can successfully generate a valid, one-step Lean proof for a simple proposition generated by the \texttt{CurriculumAgent}. The \texttt{LeanTool} must successfully verify that the generated proof is correct.\end{document}
\documentclass{article}
\usepackage[utf8]{inputenc}
\usepackage{geometry}
\geometry{a4paper, margin=1in}
\usepackage{hyperref}

\title{\textbf{Project Prometheus v0.4 Work Plan: The Autonomous Mathematician}}
\author{Generated by Gemini}
\date{\today}

\begin{document}

\maketitle

\begin{abstract}
This document outlines the detailed work plan for the next major phase of the Project Prometheus demonstrator, v0.4. This phase, titled "The Autonomous Mathematician," is designed to transition the system from demonstrating basic capabilities to tackling genuinely complex problems that require multi-step, strategic reasoning. Where v0.3 proved a single, simple theorem, v0.4 will implement a sophisticated reasoning engine capable of navigating complex proof searches, learning from its mistakes, and beginning to exhibit the kind of abstract reasoning that is a core requirement for ultraintelligence as defined in the project's foundational documents.
\end{abstract}

\hrulefill
\vspace{2em}

\section{Task 1: Implement a Multi-Step Reasoning Engine}

\subsection{Rationale}
As per the roadmap (Phase 3), the system must move beyond simple, single-shot tasks and demonstrate performance in a complex, formal domain. Real mathematical theorem proving is not a single action but a sequence of logical steps. This task upgrades the agent from a simple "prover" to a "reasoner" that can build a proof step-by-step.

\subsection{Methodology}
\begin{enumerate}
    \item \textbf{Proof State Management:} Implement a \texttt{ProofState} class within the \texttt{LeanTool}. This class will be responsible for parsing the output from the Lean server to track the current goals, hypotheses, and the overall state of the proof.
    \item \textbf{Tactic Generation in \texttt{CoderAgent}:} The \texttt{CoderAgent}'s \texttt{prove} method will be refactored. Instead of attempting to generate a complete proof, it will now be a \texttt{generate\_tactic} method that takes a \texttt{ProofState} as input and generates the single, most promising Lean tactic to apply next.
    \item \textbf{Iterative Proof Loop in \texttt{MCSSupervisor}:} The \texttt{MCSSupervisor} will be upgraded with a \texttt{run\_proof\_cycle} method. This method will manage an iterative loop:
        \begin{enumerate}
            \item Initialize the proof with the theorem and get the initial \texttt{ProofState} from the \texttt{LeanTool}.
            \item Pass the current \texttt{ProofState} to the \texttt{CoderAgent} to generate the next tactic.
            \item Apply the generated tactic using the \texttt{LeanTool}.
            \item Repeat the cycle until the \texttt{LeanTool} reports "goals accomplished" or a specified step limit is reached.
        \end{enumerate}
\end{enumerate}

\subsection{Deliverables}
\begin{itemize}
    \item An updated \texttt{LeanTool} with a \texttt{ProofState} management class.
    \item An updated \texttt{CoderAgent} with a \texttt{generate\_tactic} method for iterative reasoning.
    \item A new \texttt{run\_proof\_cycle} method in the \texttt{MCSSupervisor} to orchestrate the multi-step proof process.
\end{itemize}

\subsection{Verification}
The system can successfully prove a theorem that requires at least three sequential, distinct tactics in Lean, demonstrating its ability to build a coherent line of reasoning.

\section{Task 2: Implement a "Proof Tree" Search Strategy}

\subsection{Rationale}
A linear, step-by-step reasoning process will inevitably get stuck on complex problems. To tackle a "grand challenge" (Phase 3), the agent must be able to explore different lines of reasoning, backtrack from dead ends, and strategically choose the most promising path. This task implements a "Tree-of-Thought" search mechanism, a crucial step towards more robust problem-solving.

\subsection{Methodology}
\begin{enumerate}
    \item \textbf{Proof Tree Data Structure:} Implement a \texttt{ProofTree} class. Each node in the tree will represent a \texttt{ProofState}, and the edges will represent the tactics applied. This creates a complete, machine-readable history of the agent's reasoning process.
    \item \textbf{Heuristic Search in \texttt{PlannerAgent}:} The \texttt{PlannerAgent} will be upgraded to act as a "search strategist." Its prompt will be enhanced to take the entire \texttt{ProofTree} as input. Its task will be to analyze the tree and identify the most promising node (i.e., the most promising partial proof) to expand next. This introduces a layer of meta-cognition, where the agent reflects on its own reasoning process.
    \item \textbf{Update \texttt{MCSSupervisor} for Tree Search:} The \texttt{run\_proof\_cycle} will be updated to manage the tree search. It will build the \texttt{ProofTree} and, at each step, consult the \texttt{PlannerAgent} to decide which branch to explore. If a tactic results in an error, that branch is marked as "failed," and the supervisor will ask the \texttt{PlannerAgent} to choose a different, more promising branch.
\end{enumerate}

\subsection{Deliverables}
\begin{itemize}
    \item A \texttt{ProofTree} class for managing the search space.
    \item An updated \texttt{PlannerAgent} that can analyze the \texttt{ProofTree} and guide the search.
    \item An \texttt{MCSSupervisor} capable of managing the tree search, including backtracking from failed proof attempts.
\end{itemize}

\subsection{Verification}
The agent can successfully solve a theorem where a simple, linear ("greedy") application of tactics would fail. The logs must clearly show the agent exploring one branch, hitting a dead end, backtracking, and then successfully finding the proof along a different branch.

\section{Task 3: Refine Meta-Learning - Learning from Failed Proofs}

\subsection{Rationale}
This task directly implements the "Refine Meta-Learning capabilities" goal from the roadmap (Phase 3, Task 4). A truly intelligent agent should not just backtrack from failure; it should \textit{learn} from it. This task gives the system a "memory" of its mistakes, allowing it to refine its own proof strategies over time.

\subsection{Methodology}
\begin{enumerate}
    \item \textbf{Failure Analysis in \texttt{EvaluatorAgent}:} The \texttt{EvaluatorAgent} will be given a new role in the theorem-proving process. When a proof branch fails, the \texttt{EvaluatorAgent} will receive the failed sequence of tactics and the final Lean error message. It will then use the LLM to generate a concise, natural-language "critique" of the failed strategy.
        \begin{itemize}
            \item \textbf{Example Critique:} "The agent attempted to use a rewrite tactic (\texttt{rw}) before the necessary preconditions were met. The \texttt{induction} tactic should have been used first to break the problem into base and inductive cases."
        \end{itemize}
    \item \textbf{Update \texttt{PlannerAgent} with Contextual Memory:} The \texttt{PlannerAgent}'s prompt for guiding the tree search will be updated to include a list of the critiques from all previously failed branches. This provides the agent with a contextual "memory," allowing it to avoid repeating the same category of mistake.
\end{enumerate}

\subsection{Deliverables}
\begin{itemize}
    \item An updated \texttt{EvaluatorAgent} with a \texttt{critique\_failed\_proof} method.
    \item An updated \texttt{PlannerAgent} that incorporates this historical feedback into its search strategy.
\end{itemize}

\subsection{Verification}
After failing to prove a theorem using one strategy, the system can use the generated critique to successfully prove the same theorem on a subsequent attempt, and the logs show that it explicitly avoids the previously failed line of reasoning.

\end{document}